<?xml version='1.1' encoding='UTF-8'?>
<project>
  <actions/>
  <description></description>
  <keepDependencies>false</keepDependencies>
  <properties/>
  <scm class="hudson.plugins.git.GitSCM" plugin="git@4.3.0">
    <configVersion>2</configVersion>
    <userRemoteConfigs>
      <hudson.plugins.git.UserRemoteConfig>
        <url>https://github.com/hms-dbmi/ETL-MissionControl-dbgap-submodule</url>
      </hudson.plugins.git.UserRemoteConfig>
    </userRemoteConfigs>
    <branches>
      <hudson.plugins.git.BranchSpec>
        <name>*/master</name>
      </hudson.plugins.git.BranchSpec>
    </branches>
    <doGenerateSubmoduleConfigurations>false</doGenerateSubmoduleConfigurations>
    <submoduleCfg class="list"/>
    <extensions/>
  </scm>
  <canRoam>true</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <triggers/>
  <concurrentBuild>false</concurrentBuild>
  <builders>
    <hudson.tasks.Shell>
      <command>#!/bin/bash


mkdir completed
mkdir hierarchies
mkdir processing

mkdir data
find data/ -exec rm -rf {} \;
# Managed Inputs
aws s3 cp s3://avillach-73-bdcatalyst-etl/general/resources/Managed_Inputs.csv data/

IFS=$&apos;\r\n&apos; GLOBIGNORE=&apos;*&apos; command eval  &apos;studyids=($(cut -d , -f 1 data/Managed_Inputs.csv | grep -v Study\ Abbr | uniq))&apos;

#### get all subject multi files, job.config and patient mapping file from each study 
for studyid in ${studyids[@]}; do

	aws s3 cp s3://avillach-73-bdcatalyst-etl/${studyid,,}/data/${studyid^^}_PatientMapping.v2.csv data/

	aws s3 cp s3://avillach-73-bdcatalyst-etl/${studyid,,}/rawData/ data/ --recursive --exclude &quot;*&quot; --include &quot;*subject.multi*.txt&quot; --include &quot;*Subject.Multi*.txt&quot; --include &quot;*Subject.MULTI*.txt&quot; --include &quot;*subject.MULTI*.txt&quot;

done

java -jar jars/CleanupPatientNums.jar

ts=$(date +&quot;%Y-%m-%d_%H-%M-%S&quot;)

for studyid in ${studyids[@]}; do

	
    aws s3 cp s3://avillach-73-bdcatalyst-etl/${studyid,,}/data/${studyid^^}_PatientMapping.v2.csv s3://avillach-73-bdcatalyst-etl/${studyid,,}/data/${studyid^^}_PatientMapping.v2.csv_${ts}
	
	aws s3 cp completed/${studyid^^}_PatientMapping.v2.csv s3://avillach-73-bdcatalyst-etl/${studyid,,}/data/${studyid^^}_PatientMapping.v2.csv 

done</command>
    </hudson.tasks.Shell>
  </builders>
  <publishers/>
  <buildWrappers/>
</project>